---
title: "Recalling Words"
output: 
  html_document:
    theme: cerulean
    code_folding: hide
---

<script type="text/javascript">
 function showhide(id) {
    var e = document.getElementById(id);
    e.style.display = (e.style.display == 'block') ? 'none' : 'block';
 }
</script>

```{r load libraries, include=FALSE}
library(mosaic)
library(car)
library(pander)
library(DT) #You may need to run: install.packages("DT") 
```

```{r examine data, eval=FALSE}
# Play the chunk above and this one to get the data into your Console
View(Friendly)
?Friendly
```


<br />

## Background

Education is a very expensive industry with whose influence can make or break nations. Due to this, it's very important that educators use the best methods available for helping students to learn.

A study was performed to determine whether one of three teaching methods (named *SFR*, *Before*, and *Meshed*) had a better impact on memory recall than the others.

- The SFR method randomly presents information for memorization during each trial session.
- The Before method presents the information successfully memorized before information not memorized in each successive trial session.
- The Meshed method alternates presenting the information successfully memorized with information not memorized.

Further details are included below in "The Experiment" section.




<div style="padding-left:15px;">

##### <a href="javascript:showhide('uniquename')">Click here for further details </a>


<div id="uniquename" style="display:none;">

Individuals were seated at a computer and shown a list of words. Words appeared on the screen one at a time, for two seconds each, until all words had been shown (40 total). After all words were shown, they were required to perform a few two-digit mathematical additions (like 15 + 25) for 15 seconds to avoid immediate memory recall of the words. They were then asked to write down as many of the 40 words as they could remember. They were given a maximum of 5.3 minutes to recall words.

The process of showing words and recalling words was repeated four times with the same list of words each time (four chances to get it right). The presentation of the first trial was the same for all treatment conditions. However, trials 2, 3, and 4 were slightly different for each treatment condition.

<div style="padding-left:15px;">

The `SFR` group (the control group) stands for Standard Free Recall. In all four trials the same list of 40 words was presented, in a random order each time.

The `Before` group also used the same 40 words during each trial. However, any words that were correctly recalled in a previous trial were presented first, or *before* the words that were not recalled in the last trial. After all the correct words were presented in random order, the non-recalled words were presented in a random order.

The `Meshed` group also used the same 40 words during each trial. However, words that were correctly recalled in a previous trial were alternated with a missed word during the next presentation order. 

</div>

The data records the number of correctly recalled words (out of the 40 possible) from the fourth trial. Results were obtained for 30 students, 10 in each of the three treatment groups: `SFR`, `Before`, and `Meshed`. 

</div>

##### <a href="javascript:showhide('uniquename2')"> Click here to see the raw data </a>

<div id="uniquename2" style="display:none;">

The results from the study can be found in the `Friendly` data set in R after loading `library(car)`. 

Click the "Code" button to see the data.


```{r }
datatable(Friendly, options=list(lengthMenu = c(10,30)))

```


</div>
</div>

## Analysis

### Hypothesis
<!-- Note that your goal is to use the Friendly data to show whether or not the Meshed or Before methods have any positive benefit on memory recall. -->

We'll be testing to see if the two treatment groups, the ones that used the "Meshed" or "Before" methods, had the same difference in their medians when compared to the control group that used the "SFR" method. 

This will require two independent samples tests: Meshed compared to SFR and Before compared to SFR. The Hypothesis and $\alpha$ are as follows.

$$H_0: \text{difference in medians = 0}$$

$$H_a: \text{difference in medians > 0}$$

Normally our $\alpha$ would equal .05 but since we will need to run multiple tests, I'll conduct a Bonferroni correction and set $\alpha = .025$ for each of the tests.
$$\alpha = .025$$

Before we can determine what type of test we can do, we will need to check the normality of our data.


### Describe the Data

We'll start by creating a number summary and a strip chart. From these we can see that the sample size is too small to assume normality.


```{r}
Friendly %>% 
  group_by(condition) %>% 
  summarise(min = min(correct),
            Q1 = quantile(correct, 0.25),
            mean = mean(correct), 
            median = median(correct), 
            Q3 = quantile(correct, 0.75),
            max = max(correct),
            sd = sd(correct),
            "Sample Size" = n()
            ) %>%
  pander()
```
This stipchart seems to show that the Before method has the highest average score which the median seems to confirm in the number summary. 
```{r}
stripchart(correct ~ condition,
           data = Friendly, 
           method = "stack")
```
Since the sample size is small we'll create a Q-Q plot of each of the three samples to check for normality. Most of the data appears to be normal, however since there are outliers and the sample is small we won't be able to perform a t-Test and will need to conduct a Wilcoxon Test instead.
```{r Check for Normality}
qqPlot(correct ~ condition,
       data = Friendly)
```





### Make inferences

Now that we have determined what type of test we'll conduct, I'll set the official hypothesis.

The Wilcoxon Rank Sum Tests are as follows:

```{r Wilcoxon Rank Sum Test 1, warning = FALSE, message = FALSE}
wilcox.test(
  Friendly$correct[Friendly$condition == "Before"],
  Friendly$correct[Friendly$condition == "SFR"],
  mu = 0,
  alternative = "greater",
  conf.level = 0.95
) %>% 
  pander()
```

```{r Wilcoxon Rank Sum Test 2, warning = FALSE, message = FALSE}
wilcox.test(
  Friendly$correct[Friendly$condition == "Meshed"],
  Friendly$correct[Friendly$condition == "SFR"],
  mu = 0,
  alternative = "greater",
  conf.level = 0.95
) %>% 
  pander()
```

Since the p-value for the "Before" method hypothesis is 0.02278, we have sufficient evidence to reject the null hypothesis for the "Before" method. 

Since the p-value for the "Meshed" method hypothesis is 0.05075, we have insufficient evidence to reject the null hypothesis for the "Meshed" method.

### Conclusion

According to the Wilcoxon test, we have sufficient evidence that  the "Before" method performed better than the "Meshed" method and the "SFR" method. Despite this however, it is important to note that the sample size was very small, thus we may be at risk of a false positive result. Based on this information it may be appropriate to assume that funding this same experiment, but with a larger sample size, might yield conclusive evidence.

